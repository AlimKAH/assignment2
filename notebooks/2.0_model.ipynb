{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scipy) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import surprise\n",
    "from surprise import SVD\n",
    "from surprise import Reader, Dataset\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset and label encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>b'24-Jan-1997'</td>\n",
       "      <td>49</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>55105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196</td>\n",
       "      <td>257</td>\n",
       "      <td>2</td>\n",
       "      <td>Men in Black (1997)</td>\n",
       "      <td>b'04-Jul-1997'</td>\n",
       "      <td>49</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>55105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>Truth About Cats &amp; Dogs, The (1996)</td>\n",
       "      <td>b'26-Apr-1996'</td>\n",
       "      <td>49</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>55105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>Birdcage, The (1996)</td>\n",
       "      <td>b'08-Mar-1996'</td>\n",
       "      <td>49</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>55105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196</td>\n",
       "      <td>382</td>\n",
       "      <td>4</td>\n",
       "      <td>Adventures of Priscilla, Queen of the Desert, ...</td>\n",
       "      <td>b'01-Jan-1994'</td>\n",
       "      <td>49</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>55105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  \\\n",
       "0      196       242       3   \n",
       "1      196       257       2   \n",
       "2      196       111       4   \n",
       "3      196        25       4   \n",
       "4      196       382       4   \n",
       "\n",
       "                                               title    release_date  age sex  \\\n",
       "0                                       Kolya (1996)  b'24-Jan-1997'   49   M   \n",
       "1                                Men in Black (1997)  b'04-Jul-1997'   49   M   \n",
       "2                Truth About Cats & Dogs, The (1996)  b'26-Apr-1996'   49   M   \n",
       "3                               Birdcage, The (1996)  b'08-Mar-1996'   49   M   \n",
       "4  Adventures of Priscilla, Queen of the Desert, ...  b'01-Jan-1994'   49   M   \n",
       "\n",
       "  occupation zip_code  \n",
       "0     writer    55105  \n",
       "1     writer    55105  \n",
       "2     writer    55105  \n",
       "3     writer    55105  \n",
       "4     writer    55105  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/internim/user_movie_ratings.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['title', 'release_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85103</th>\n",
       "      <td>591</td>\n",
       "      <td>523</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>librarian</td>\n",
       "      <td>92093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87142</th>\n",
       "      <td>829</td>\n",
       "      <td>318</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>80209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53001</th>\n",
       "      <td>711</td>\n",
       "      <td>941</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>F</td>\n",
       "      <td>student</td>\n",
       "      <td>15203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34610</th>\n",
       "      <td>802</td>\n",
       "      <td>288</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "      <td>34105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26045</th>\n",
       "      <td>450</td>\n",
       "      <td>629</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>educator</td>\n",
       "      <td>11758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating  age sex     occupation zip_code\n",
       "85103      591       523       4   57   F      librarian    92093\n",
       "87142      829       318       5   48   M         writer    80209\n",
       "53001      711       941       3   22   F        student    15203\n",
       "34610      802       288       3   35   M  administrator    34105\n",
       "26045      450       629       4   35   F       educator    11758"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "data['sex'] = label_encoder.fit_transform(data['sex'])\n",
    "data['occupation'] = label_encoder.fit_transform(data['occupation'])\n",
    "data['zip_code'] = label_encoder.fit_transform(data['zip_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20800</th>\n",
       "      <td>405</td>\n",
       "      <td>949</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80757</th>\n",
       "      <td>815</td>\n",
       "      <td>479</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>296</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71315</th>\n",
       "      <td>407</td>\n",
       "      <td>705</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4428</th>\n",
       "      <td>202</td>\n",
       "      <td>318</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating  age  sex  occupation  zip_code\n",
       "20800      405       949       5   22    0           7        93\n",
       "80757      815       479       4   32    1          13       239\n",
       "360        296        13       3   43    0           0       144\n",
       "71315      407       705       4   29    1           4        41\n",
       "4428       202       318       1   41    0           3       467"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's perform matrix formalization using Surprise library.\n",
    "\n",
    "Used to incorporate collaborative filtering into our solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split 80/20\n",
    "\n",
    "train_data=data.iloc[:int(data.shape[0]*0.80)]\n",
    "test_data=data.iloc[int(data.shape[0]*0.80):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80000, 7), (20000, 7))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape ,test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standart Reader from surprise lib\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "\n",
    "# Creating train and test data sets using surprise library\n",
    "\n",
    "train_data_mf = Dataset.load_from_df(train_data[['user_id', 'movie_id', 'rating']], reader)\n",
    "trainset = train_data_mf.build_full_trainset() \n",
    "\n",
    "test_data_mf = Dataset.load_from_df(test_data[['user_id', 'movie_id', 'rating']], reader)\n",
    "testset = test_data_mf.build_full_trainset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x238b286ddb0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's set the baseline for our model using SVD from surprise Lib. We can use this result to enhance our main model \n",
    "\n",
    "svd = SVD(n_factors=100, biased=True, random_state=42, verbose=True)\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predictions and storing them to pass a later\n",
    "\n",
    "train_preds = svd.test(trainset.build_testset())\n",
    "train_pred_mf = np.array([pred.est for pred in train_preds])\n",
    "\n",
    "test_preds = svd.test(testset.build_testset())\n",
    "test_pred_mf = np.array([pred.est for pred in test_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For train data:\n",
      "RMSE: 0.6674\n",
      "MAE:  0.5281\n",
      "For test data:\n",
      "RMSE: 1.0558\n",
      "MAE:  0.8423\n"
     ]
    }
   ],
   "source": [
    "# Calculating RMSE and MAE, for baseline\n",
    "print(\"For train data:\")\n",
    "train_rmse = surprise.accuracy.rmse(train_preds, verbose=True) \n",
    "train_mae = surprise.accuracy.mae(train_preds, verbose=True)\n",
    "print(\"For test data:\")\n",
    "test_rmse = surprise.accuracy.rmse(test_preds, verbose=True)\n",
    "test_mae = surprise.accuracy.mae(test_preds, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's add some features\n",
    "Mainly: \n",
    "* Similar users(top 5)\n",
    "* Similar movies(top 5, by ratings)\n",
    "\n",
    "Global average for:\n",
    "* Avg rating for all movies by users\n",
    "* Avg rating for movie by all the users\n",
    "* Avg rating for all movies by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sparse_matrix = sparse.csr_matrix((train_data.rating.values, (train_data.user_id.values,\n",
    "                                               train_data.movie_id.values))) # Introduce a sparse matrix for better performance\n",
    "test_sparse_matrix = sparse.csr_matrix((test_data.rating.values, (test_data.user_id.values,\n",
    "                                               test_data.movie_id.values)))\n",
    "\n",
    "# Function to return user averages\n",
    "\n",
    "def average_ratings(matrix, users):\n",
    "    axis = 1 if users else 0\n",
    "    sum_of_ratings = matrix.sum(axis=axis).A1\n",
    "    is_rated = matrix != 0\n",
    "    no_of_ratings = is_rated.sum(axis=axis).A1\n",
    "    user, movie = matrix.shape\n",
    "    avg_ratings = { i : sum_of_ratings[i]/no_of_ratings[i]\n",
    "                                for i in range(user if users else movie) \n",
    "                                if no_of_ratings[i] != 0}\n",
    "    return avg_ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'global': 3.5157375}\n"
     ]
    }
   ],
   "source": [
    "# Calculating average rating for all movies\n",
    "train_averages = dict()\n",
    "train_global_average = train_sparse_matrix.sum()/train_sparse_matrix.count_nonzero()\n",
    "train_averages['global'] = train_global_average\n",
    "print(train_averages)\n",
    "\n",
    "test_averages = dict()\n",
    "test_global_average = test_sparse_matrix.sum()/test_sparse_matrix.count_nonzero()\n",
    "test_averages['global'] = test_global_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg rating for 5 users from data: \n",
      "{1: 3.610294117647059, 2: 3.7096774193548385, 3: 2.7962962962962963, 5: 2.874285714285714, 6: 3.6350710900473935}\n",
      "Avg rating for 5 movies from data: \n",
      "{1: 3.8435374149659864, 2: 3.2241379310344827, 3: 3.0, 4: 3.543956043956044, 5: 3.26027397260274}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "train_averages['user'] = average_ratings(train_sparse_matrix, users=True)\n",
    "out = dict(itertools.islice(train_averages['user'].items(), 5))\n",
    "print(\"Avg rating for 5 users from data: \\n\" +  str(out))\n",
    "\n",
    "train_averages['movie'] =  average_ratings(train_sparse_matrix, users=False)\n",
    "out = dict(itertools.islice(train_averages['movie'].items(), 5))\n",
    "print(\"Avg rating for 5 movies from data: \\n\" +  str(out))\n",
    "\n",
    "test_averages['user'] = average_ratings(test_sparse_matrix, users=True)\n",
    "test_averages['movie'] =  average_ratings(test_sparse_matrix, users=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users, train_movies, train_ratings = sparse.find(train_sparse_matrix)\n",
    "test_users, test_movies, test_ratings = sparse.find(test_sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\PycharmProjects\\PMLDL\\Assignment_2\\notebooks\\2.0_model.ipynb Cell 21\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/PMLDL/Assignment_2/notebooks/2.0_model.ipynb#X26sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m         dataframe \u001b[39m=\u001b[39m dataframe\u001b[39m.\u001b[39mappend([data_obtained])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/PMLDL/Assignment_2/notebooks/2.0_model.ipynb#X26sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m dataframe\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/PMLDL/Assignment_2/notebooks/2.0_model.ipynb#X26sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m train_df \u001b[39m=\u001b[39m collect_dataframe(train_df,  train_users, train_movies, train_ratings, train_averages)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/PMLDL/Assignment_2/notebooks/2.0_model.ipynb#X26sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m test_df \u001b[39m=\u001b[39m collect_dataframe(test_df,  test_users, test_movies, test_ratings, test_averages)\n",
      "\u001b[1;32mc:\\Users\\User\\PycharmProjects\\PMLDL\\Assignment_2\\notebooks\\2.0_model.ipynb Cell 21\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/PMLDL/Assignment_2/notebooks/2.0_model.ipynb#X26sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     data_obtained\u001b[39m.\u001b[39mappend(averages[\u001b[39m'\u001b[39m\u001b[39mmovie\u001b[39m\u001b[39m'\u001b[39m][mov])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/PMLDL/Assignment_2/notebooks/2.0_model.ipynb#X26sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     data_obtained\u001b[39m.\u001b[39mappend(rat)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/PMLDL/Assignment_2/notebooks/2.0_model.ipynb#X26sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     dataframe \u001b[39m=\u001b[39m dataframe\u001b[39m.\u001b[39;49mappend([data_obtained])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/PycharmProjects/PMLDL/Assignment_2/notebooks/2.0_model.ipynb#X26sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mreturn\u001b[39;00m dataframe\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:9768\u001b[0m, in \u001b[0;36mDataFrame.append\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   9665\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   9666\u001b[0m \u001b[39mAppend rows of `other` to the end of caller, returning a new object.\u001b[39;00m\n\u001b[0;32m   9667\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9758\u001b[0m \u001b[39m4  4\u001b[39;00m\n\u001b[0;32m   9759\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   9760\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   9761\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mThe frame.append method is deprecated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   9762\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mand will be removed from pandas in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9765\u001b[0m     stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   9766\u001b[0m )\n\u001b[1;32m-> 9768\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_append(other, ignore_index, verify_integrity, sort)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:9808\u001b[0m, in \u001b[0;36mDataFrame._append\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   9805\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   9806\u001b[0m     to_concat \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m, other]\n\u001b[1;32m-> 9808\u001b[0m result \u001b[39m=\u001b[39m concat(\n\u001b[0;32m   9809\u001b[0m     to_concat,\n\u001b[0;32m   9810\u001b[0m     ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[0;32m   9811\u001b[0m     verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[0;32m   9812\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   9813\u001b[0m )\n\u001b[0;32m   9814\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mappend\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39m1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    368\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m     objs,\n\u001b[0;32m    370\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    378\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[0;32m    379\u001b[0m )\n\u001b[1;32m--> 381\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    612\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    614\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 616\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[0;32m    617\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_axes, concat_axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbm_axis, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[0;32m    618\u001b[0m )\n\u001b[0;32m    619\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy:\n\u001b[0;32m    620\u001b[0m     new_data\u001b[39m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\concat.py:233\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    231\u001b[0m     fastpath \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m values\u001b[39m.\u001b[39mdtype\n\u001b[0;32m    232\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 233\u001b[0m     values \u001b[39m=\u001b[39m _concatenate_join_units(join_units, concat_axis, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    234\u001b[0m     fastpath \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m fastpath:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\concat.py:577\u001b[0m, in \u001b[0;36m_concatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m    574\u001b[0m     concat_values \u001b[39m=\u001b[39m ensure_block_shape(concat_values, \u001b[39m2\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     concat_values \u001b[39m=\u001b[39m concat_compat(to_concat, axis\u001b[39m=\u001b[39;49mconcat_axis)\n\u001b[0;32m    579\u001b[0m \u001b[39mreturn\u001b[39;00m concat_values\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\dtypes\\concat.py:151\u001b[0m, in \u001b[0;36mconcat_compat\u001b[1;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[0;32m    148\u001b[0m             to_concat \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mastype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m to_concat]\n\u001b[0;32m    149\u001b[0m             kinds \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mo\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m--> 151\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate(to_concat, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m    152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kinds \u001b[39mand\u001b[39;00m result\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    153\u001b[0m     \u001b[39m# GH#39817\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    155\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mBehavior when concatenating bool-dtype and numeric-dtype arrays is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdeprecated; in a future version these will cast to object dtype \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    161\u001b[0m     )\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "train_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "def collect_dataframe(dataframe, users, movies, ratings, averages):\n",
    "    for (usr, mov, rat) in zip(users, movies, ratings):\n",
    "        if dataframe is train_df:\n",
    "            # Get the similar movies to the current movie rated by part. user\n",
    "            movie_sim = cosine_similarity(train_sparse_matrix[:, mov].T, train_sparse_matrix.T).ravel()\n",
    "            top_sim_movies = movie_sim.argsort()[::-1][1:]\n",
    "            top_ratings_mov = train_sparse_matrix[usr, top_sim_movies].toarray().ravel()\n",
    "            top_sim_movies_ratings = list(top_ratings_mov[top_ratings_mov != 0][:5])\n",
    "            top_sim_movies_ratings.extend([train_averages['user'][usr]] * (5 - len(top_sim_movies_ratings)))\n",
    "\n",
    "            # Get the similar users to the current user\n",
    "            user_sim = cosine_similarity(train_sparse_matrix[usr], train_sparse_matrix).ravel()\n",
    "            top_sim_users = user_sim.argsort()[::-1][1:]\n",
    "            top_ratings_usr = train_sparse_matrix[top_sim_users, mov].toarray().ravel()\n",
    "            top_sim_users_ratings = list(top_ratings_usr[top_ratings_usr != 0][:5])\n",
    "            top_sim_users_ratings.extend([train_averages['movie'][mov]] * (5 - len(top_sim_users_ratings)))\n",
    "        \n",
    "        elif dataframe is test_df:\n",
    "            user_sim = cosine_similarity(test_sparse_matrix[usr], test_sparse_matrix).ravel()\n",
    "            top_sim_users = user_sim.argsort()[::-1][1:]\n",
    "            top_ratings_usr = test_sparse_matrix[top_sim_users, mov].toarray().ravel()\n",
    "            top_sim_users_ratings = list(top_ratings_usr[top_ratings_usr != 0][:5])\n",
    "            top_sim_users_ratings.extend([test_averages['movie'][mov]]*(5 - len(top_sim_users_ratings)))\n",
    "\n",
    "            movie_sim = cosine_similarity(test_sparse_matrix[:,mov].T, test_sparse_matrix.T).ravel()\n",
    "            top_sim_movies = movie_sim.argsort()[::-1][1:]\n",
    "            top_ratings = test_sparse_matrix[usr, top_sim_movies].toarray().ravel()\n",
    "            top_sim_movies_ratings = list(top_ratings[top_ratings != 0][:5])\n",
    "            top_sim_movies_ratings.extend([test_averages['user'][usr]]*(5-len(top_sim_movies_ratings)))\n",
    "\n",
    "\n",
    "        # Collect everything to the dataset\n",
    "        data_obtained = list()\n",
    "        data_obtained.append(usr)\n",
    "        data_obtained.append(mov)\n",
    "        data_obtained.append(averages['global'])\n",
    "        data_obtained.extend(top_sim_users_ratings)\n",
    "        data_obtained.extend(top_sim_movies_ratings)\n",
    "        data_obtained.append(averages['user'][usr])\n",
    "        data_obtained.append(averages['movie'][mov])\n",
    "        data_obtained.append(rat)\n",
    "\n",
    "        dataframe = dataframe.append([data_obtained])\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "train_df = collect_dataframe(train_df,  train_users, train_movies, train_ratings, train_averages)\n",
    "test_df = collect_dataframe(test_df,  test_users, test_movies, test_ratings, test_averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 16)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns=['user', 'movie', 'AvgR', 'sim_rat_u1', 'sim_rat_u2', 'sim_rat_u3', 'sim_rat_u4', 'sim_rat_u5',\n",
    "            'sim_rat_m1', 'sim_rat_m2', 'sim_rat_m3', 'sim_rat_m4', 'sim_rat_m5', 'Usr_Avg', 'Mov_Avg', 'rating']\n",
    "\n",
    "train_df['svd_mf'] = train_pred_mf\n",
    "\n",
    "test_df.columns=['user', 'movie', 'AvgR', 'sim_rat_u1', 'sim_rat_u2', 'sim_rat_u3', 'sim_rat_u4', 'sim_rat_u5',\n",
    "            'sim_rat_m1', 'sim_rat_m2', 'sim_rat_m3', 'sim_rat_m4', 'sim_rat_m5', 'Usr_Avg', 'Mov_Avg', 'rating']\n",
    "\n",
    "test_df['svd_mf'] = test_pred_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save resulting df's as it takes time to collect the dataset\n",
    "\n",
    "train_df.to_csv('../data/external/final_train_svd.csv', index=False)\n",
    "test_df.to_csv('../data/external/final_test_svd.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing XGBoost model:\n",
    "\n",
    "There I have implemented the XGBoost model and got some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(np.mean([ (y_true[i] - y_pred[i])**2 for i in range(len(y_pred)) ]))\n",
    "    mape = np.mean(np.abs( (y_true - y_pred)/y_true )) * 100\n",
    "    return rmse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.drop(['user', 'movie','rating'], axis=1)\n",
    "y_train = train_df['rating']\n",
    "\n",
    "x_test = test_df.drop(['user','movie','rating'], axis=1)\n",
    "y_test = test_df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model..\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor(silent=False, n_jobs=13, random_state=15, n_estimators=100)\n",
    "\n",
    "\n",
    "train_results = dict()\n",
    "test_results = dict()\n",
    "\n",
    "print('Training the model..')\n",
    "xgb_model.fit(x_train, y_train, eval_metric = 'rmse')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Test data\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = xgb_model.predict(x_test) \n",
    "rmse_test, mape_test = get_error_metrics(y_true=y_test.values, y_pred=y_test_pred)\n",
    "test_results = {'rmse': rmse_test,\n",
    "                    'mape' : mape_test,\n",
    "                    'predictions':y_test_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 0.9601231849841207,\n",
       " 'mape': 30.362102796668804,\n",
       " 'predictions': array([3.4052298, 3.2814798, 3.9577622, ..., 2.0483723, 1.7854112,\n",
       "        3.6811721], dtype=float32)}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results # Evaluation of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets look at some predictions!\n",
    "\n",
    "Considering the fact, that model never seen this data, we can suggest user some movies, based on predicted rating that might be interesting to him/her"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predicted_rating'] = xgb_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user  movie  predicted_rating\n",
      "98     17    471          3.589669\n",
      "104    17    269          3.548952\n",
      "102    17    100          3.513165\n",
      "86     17    475          3.463399\n",
      "85     17    744          3.454559\n"
     ]
    }
   ],
   "source": [
    "recommendations = pd.read_csv('../references/user_recs.csv')\n",
    "\n",
    "def print_user_ratings(recommendations_df, user_id, top_n):\n",
    "    user_ratings = recommendations_df[recommendations_df['user'] == user_id]\n",
    "    user_ratings = user_ratings.sort_values(by='predicted_rating', ascending=False).head(top_n)\n",
    "    \n",
    "    print(user_ratings)\n",
    "\n",
    "user_id = 17\n",
    "top_n = 5 \n",
    "print_user_ratings(recommendations, user_id, top_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations.to_csv('../references/user_recs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.save_model('../models/model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.Booster()\n",
    "xgb_model.load_model('../models/model.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
